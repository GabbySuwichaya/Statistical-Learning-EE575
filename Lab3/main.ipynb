{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratory 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Inference EE 2102575."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/GabbySuwichaya/Statistical-Learning-EE575/blob/master/Lab3/main.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instruction. \n",
    "\n",
    "You may use the following implementations to answer the questions in the answering sheet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy \n",
    "# ! pip install -U matplotlib\n",
    "# ! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import file and preprocessing for Q2-Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we are going to classify an individual whether he/she can get the loan amount based on his/her Income, Education, Working Experience, Loan taken previously, and many more factors.\n",
    "\n",
    "Letâ€™s get more into it by looking at the data.\n",
    "\n",
    "Here we used the data from https://www.kaggle.com/datasets/bhavikjikadara/loan-status-prediction?resource=download\n",
    "\n",
    "About the loan_data.csv file:\n",
    "\n",
    "- Loan_ID: A unique loan ID.\n",
    "\n",
    "- Gender: Either male or female.\n",
    "\n",
    "- Married: Weather Married(yes) or Not Marttied(No).\n",
    "\n",
    "- Dependents: Number of persons depending on the client.\n",
    "\n",
    "- Education: Applicant Education (graduated or not).\n",
    "\n",
    "- Self_Employed: Self-employed (Yes/No).\n",
    "\n",
    "- ApplicantIncome: Applicant income.\n",
    "\n",
    "- CoapplicantIncome: Co-applicant income.\n",
    "\n",
    "- LoanAmount: Loan amount in thousands.\n",
    "\n",
    "- Loan_Amount_Term: Terms of the loan in months.\n",
    "\n",
    "- Credit_History: Credit history meets guidelines.\n",
    "\n",
    "- Property_Area: Applicants are living either Urban, Semi-Urban or Rural.\n",
    "\n",
    "- Loan_Status: Loan approved (Y/N). *** Target ***\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "SMALL_SIZE = 12\n",
    "MEDIUM_SIZE = 16\n",
    "BIGGER_SIZE = 14\n",
    "\n",
    "plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "plt.rc('figure', titlesize=BIGGER_SIZE)  # fontsize of the figure title\n",
    "\n",
    " \n",
    "df = pd.read_csv('loan_data.csv') \n",
    "df = df[df.notnull().all(axis=1)]\n",
    "\n",
    "\n",
    "Feat_List = ['Loan_ID', 'Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Property_Area', 'Loan_Status', 'Credit_History']\n",
    "df[Feat_List] = df.loc[:,Feat_List].apply(LabelEncoder().fit_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "cor = df.corr()\n",
    "g = sns.heatmap(cor, annot=True, cmap=plt.cm.Reds) \n",
    "g.axes.xaxis.set_ticks_position(\"top\")\n",
    "plt.setp(g.axes.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info()\n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['LoanAmount', 'Education', 'Loan_Status']] \n",
    "dataplot = sns.heatmap(data.corr(), cmap=\"YlGnBu\", annot=True) \n",
    "plt.savefig('Confusion_matrix_LEL.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Loan amounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are a banker, will you give the loan to this person?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loan amount vs Loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.loc[:, 'LoanAmount' ].values\n",
    "Y = df['Loan_Status'].values.reshape(-1,1)  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
    "\n",
    "\n",
    "log_reg = sm.Logit(y_train, X_train).fit() \n",
    "print(log_reg.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoanAmount vs Credit history vs Loan status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Selected_Feat_List = [ 'LoanAmount', 'Credit_History', 'Gender', 'Education'] #  'Gender', 'Education' \n",
    "\n",
    "X = df.loc[:, Selected_Feat_List].values\n",
    "Y = df['Loan_Status'].values.reshape(-1,1)  \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
    "\n",
    "import statsmodels.api as sm \n",
    "log_reg = sm.Logit(y_train, X_train).fit() \n",
    "\n",
    "print(log_reg.summary()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   'Loan amount'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanAmount  = X_train[:,0] \n",
    "Loanstatus  = y_train.reshape(-1)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4), sharey=True)\n",
    "\n",
    "\n",
    "all_data = [LoanAmount[Loanstatus == 0], LoanAmount[Loanstatus == 1] ]\n",
    " \n",
    "labels   = [\"Fail\", \"Pass\"]\n",
    "\n",
    "bplot1 = ax.boxplot(all_data,\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "ax.violinplot(all_data,  showmeans=False,  showmedians=True)  # will be used to label x-ticks \n",
    "ax.axhline(LoanAmount[Loanstatus == 0].mean(), color='red',  lw=1, label=\"Fail\")\n",
    "ax.axhline(LoanAmount[Loanstatus == 1].mean(), color='blue', lw=1, label=\"Pass\")\n",
    "ax.set_ylabel(r'Loan Amount $(\\times 1K$ USD)')\n",
    "ax.set_xlabel('Loan Status') \n",
    "ax.grid()\n",
    "plt.savefig('LoanAmount_vs_status.png', bbox_inches='tight')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Loan status' vs 'Credits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df[['LoanAmount', 'Credit_History', 'Loan_Status']] \n",
    "dataplot = sns.heatmap(data.corr(), cmap=\"YlGnBu\", annot=True) \n",
    "plt.savefig('Confusion_matrix.png', bbox_inches='tight')\n",
    "# ax[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Loan amount' vs 'Credits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LoanAmount  = X_train[:,0] \n",
    "Credits = X_train[:,1] \n",
    "\n",
    "labels   = [\"No\", \"Yes\"]\n",
    "all_data = [LoanAmount[Credits == 0], LoanAmount[Credits == 1] ]\n",
    "  \n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(5, 4), sharey=True)\n",
    "bplot1 = ax.boxplot(all_data,\n",
    "                     vert=True,  # vertical box alignment\n",
    "                     patch_artist=True,  # fill with color\n",
    "                     labels=labels)  # will be used to label x-ticks\n",
    "\n",
    "ax.violinplot(all_data,  showmeans=False,  showmedians=True)  # will be used to label x-ticks \n",
    "ax.axhline(LoanAmount[Credits == 0].mean(), color='red',  lw=1, label=\"No\")\n",
    "ax.axhline(LoanAmount[Credits == 1].mean(), color='blue', lw=1, label=\"Yes\")\n",
    "\n",
    "ax.set_ylabel(r'Loan Amount $(\\times 1K$ USD)')\n",
    "ax.set_xlabel('Credit. History')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.savefig('LoanAmount_vs_History.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(LoanAmount[Credits == 1], bins=25,\n",
    "         alpha=0.5, \n",
    "         label='Credit:Yes') \n",
    "\n",
    "plt.hist(LoanAmount[Credits == 0], bins=25,  \n",
    "         alpha=0.5, # the transaparency parameter \n",
    "         label='Credit:No')  \n",
    "plt.xlabel(r'Loan Amount $(\\times 1K$ USD)')\n",
    "plt.legend(loc='upper right') \n",
    "plt.ylabel('Freq. (counts)')  \n",
    "plt.grid()\n",
    "plt.savefig('LoanAmount_vs_Frq.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3-Q4 KNN, LDA, and QDA Classifiers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, settings will be used in KNN, LDA, and QDA implementation. \n",
    "\n",
    "Your target is to \n",
    "- find the best parameters for each algorithm. \n",
    "- analyze the performance of the algortihms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_TWO_feature = True\n",
    "\n",
    "if using_TWO_feature == True:\n",
    "\n",
    "    feature_list = ['Credit_History', 'LoanAmount' ]    \n",
    "    \n",
    "else:\n",
    "    feature_list =  [  'Gender', 'Married',  'LoanAmount', 'Dependents', 'Self_Employed', 'ApplicantIncome', 'CoapplicantIncome', 'Credit_History' ] \n",
    "\n",
    "X = df.loc[:, feature_list ].values\n",
    "Y = df['Loan_Status'].values.reshape(-1,1)  \n",
    "\n",
    "X_train, X_test, y_train, y_test   = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state= 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "Xscaler = MinMaxScaler()\n",
    "X_train = Xscaler.fit_transform(X_train)\n",
    "X_valid = Xscaler.transform(X_valid)\n",
    "X_test = Xscaler.transform(X_test)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import  precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "k_list = list(np.arange(1, 10, 2, dtype=int))\n",
    "precision_list = []\n",
    "recall_list = [] \n",
    "\n",
    "for k in k_list: \n",
    "    neigh = KNeighborsClassifier(n_neighbors=k)\n",
    "    neigh.fit(X_train, y_train.reshape(-1))\n",
    "    y_trainpred = neigh.predict(X_train) \n",
    "\n",
    "    y_validpred  = neigh.predict(X_valid)\n",
    "    precision_   = precision_score(y_validpred.reshape(-1), y_valid.reshape(-1))\n",
    "    recall_      = recall_score(y_validpred.reshape(-1), y_valid.reshape(-1)) \n",
    "    precision_list.append(precision_) \n",
    "    recall_list.append(recall_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q 3.1.1 What is the best $k$-based on Precision and Recall curve ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(k_list)):\n",
    "    plt.text(precision_list[i]+0.001, recall_list[i]+0.002, r\"$k$=%s\" % str(k_list[i]),alpha=0.8)\n",
    "\n",
    "plt.plot(precision_list, recall_list, 'o', color='red')   \n",
    "plt.ylabel('Recall')  \n",
    "plt.xlabel('Precision')  \n",
    "plt.grid()\n",
    "plt.savefig('k_vs_precision-recall.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3.1.2 Compare the performance against LDA & QDA on validated sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis(solver=\"svd\")\n",
    "\n",
    "lda.fit(X_train, y_train.reshape(-1))\n",
    "y_trainpred = lda.predict(X_train) \n",
    "\n",
    "y_validpred  = lda.predict(X_valid)\n",
    "precision_   = precision_score(y_validpred.reshape(-1), y_valid.reshape(-1))\n",
    "recall_      = recall_score(y_validpred.reshape(-1), y_valid.reshape(-1)) \n",
    "\n",
    "print(\"LDA: precision %f recall %f \" % (precision_, recall_) ) \n",
    "precision_list.append(precision_)    \n",
    "recall_list.append(recall_) \n",
    "k_list.append(\"LDA\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "qda.fit(X_train, y_train.reshape(-1))\n",
    "y_trainpred = qda.predict(X_train) \n",
    "\n",
    "y_validpred  = qda.predict(X_valid)\n",
    "precision_   = precision_score(y_validpred.reshape(-1), y_valid.reshape(-1))\n",
    "recall_      = recall_score(y_validpred.reshape(-1), y_valid.reshape(-1)) \n",
    "\n",
    "print(\"QDA: precision %f recall %f \" % (precision_, recall_) ) \n",
    "precision_list.append(precision_)    \n",
    "recall_list.append(recall_) \n",
    "k_list.append(\"QDA\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Which algorithm gives the best precision-recall trade-off ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(k_list)):\n",
    "    plt.text(precision_list[i]+0.001, recall_list[i]+0.002, r\"$k$=%s\" % str(k_list[i]),alpha=0.8)\n",
    "\n",
    "plt.plot(precision_list, recall_list, 'o', color='red')   \n",
    "plt.ylabel('Recall')  \n",
    "plt.xlabel('Precision')  \n",
    "plt.grid()\n",
    "plt.savefig('k_vs_precision-recall.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q 3.1.4. Compare the confusion matrices of KNN the best $k$ vs. LDA and QDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(X_train, y_train.reshape(-1))\n",
    "predictions = neigh.predict(X_test) \n",
    "cm = confusion_matrix(y_test, predictions, labels=neigh.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lda.predict(X_test) \n",
    "cm = confusion_matrix(y_test, predictions, labels=neigh.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qda.predict(X_test) \n",
    "cm = confusion_matrix(y_test, predictions, labels=neigh.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5. LDA and QDA on the data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "\n",
    "def plot_ellipse(mean, cov, color, ax):\n",
    "    v, w = np.linalg.eigh(cov)\n",
    "    u = w[0] / np.linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    # filled Gaussian at 2 standard deviation\n",
    "    ell = mpl.patches.Ellipse(\n",
    "        mean,\n",
    "        2 * v[0] ** 0.5,\n",
    "        2 * v[1] ** 0.5,\n",
    "        angle=180 + angle,\n",
    "        facecolor=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ell.set_clip_box(ax.bbox)\n",
    "    ell.set_alpha(0.4)\n",
    "    ax.add_artist(ell)\n",
    "\n",
    "\n",
    "def plot_result(estimator, X, y, ax):\n",
    "    cmap = colors.ListedColormap([\"tab:red\", \"tab:blue\"])\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        estimator,\n",
    "        X,\n",
    "        response_method=\"predict_proba\",\n",
    "        plot_method=\"pcolormesh\",\n",
    "        ax=ax,\n",
    "        cmap=\"RdBu\",\n",
    "        alpha=0.3,\n",
    "    )\n",
    "    DecisionBoundaryDisplay.from_estimator(\n",
    "        estimator,\n",
    "        X,\n",
    "        response_method=\"predict_proba\",\n",
    "        plot_method=\"contour\",\n",
    "        ax=ax,\n",
    "        alpha=1.0,\n",
    "        levels=[0.5],\n",
    "    )\n",
    "    y_pred = estimator.predict(X)\n",
    "    X_right, y_right = X[y == y_pred], y[y == y_pred]\n",
    "    X_wrong, y_wrong = X[y != y_pred], y[y != y_pred]\n",
    "    ax.scatter(X_right[:, 0], X_right[:, 1], c=y_right, s=20, cmap=cmap, alpha=0.5)\n",
    "    ax.scatter(\n",
    "        X_wrong[:, 0],\n",
    "        X_wrong[:, 1],\n",
    "        c=y_wrong,\n",
    "        s=30,\n",
    "        cmap=cmap,\n",
    "        alpha=0.9,\n",
    "        marker=\"x\",\n",
    "    )\n",
    "    ax.scatter(\n",
    "        estimator.means_[:, 0],\n",
    "        estimator.means_[:, 1],\n",
    "        c=\"yellow\",\n",
    "        s=200,\n",
    "        marker=\"*\",\n",
    "        edgecolor=\"black\",\n",
    "    )\n",
    "\n",
    "    if isinstance(estimator, LinearDiscriminantAnalysis):\n",
    "        covariance = [estimator.covariance_] * 2\n",
    "    else:\n",
    "        covariance = estimator.covariance_\n",
    "    plot_ellipse(estimator.means_[0], covariance[0], \"tab:red\", ax)\n",
    "    plot_ellipse(estimator.means_[1], covariance[1], \"tab:blue\", ax)\n",
    "\n",
    "    ax.set_box_aspect(1)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    #ax.set(xticks=[], yticks=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if using_TWO_feature == True:\n",
    "    fig, axs = plt.subplots(nrows=1, ncols=2, sharex=\"row\", sharey=\"row\", figsize=(8, 12))\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "    qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "\n",
    "\n",
    "    lda.fit(X_train, y_train.reshape(-1))\n",
    "    plot_result(lda, X_train, y_train.reshape(-1), axs[0])\n",
    "    qda.fit(X_train, y_train.reshape(-1))\n",
    "    plot_result(qda, X_train, y_train.reshape(-1), axs[1])\n",
    "\n",
    "    axs[0].set_title(\"Linear Discriminant Analysis\")\n",
    "    axs[1].set_title(\"Quadratic Discriminant Analysis\")\n",
    "    axs[0].set_ylabel(\"Data with unknon covariances\")\n",
    "    \n",
    "    plt.savefig('LDA-QDA-boundary.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q.6 Experiment on single feature (Credit_History or LoanAmount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using_Credit_History = True\n",
    "\n",
    "if using_Credit_History == True:\n",
    "\n",
    "    feature_list = ['Credit_History']    \n",
    "    \n",
    "else:\n",
    "    feature_list = ['LoanAmount']      \n",
    "\n",
    "X = df.loc[:, feature_list ].values\n",
    "Y = df['Loan_Status'].values.reshape(-1,1)  \n",
    "\n",
    "X_train, X_test, y_train, y_test   = train_test_split(X, Y, test_size=0.2, random_state= 0)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.3, random_state= 0)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "Xscaler = MinMaxScaler()\n",
    "X_train = Xscaler.fit_transform(X_train)\n",
    "X_valid = Xscaler.transform(X_valid)\n",
    "X_test = Xscaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.fit(X_train, y_train.reshape(-1))\n",
    "y_trainpred = lda.predict(X_train) \n",
    "\n",
    "y_validpred  = lda.predict(X_valid)\n",
    "precision_   = precision_score(y_validpred.reshape(-1), y_valid.reshape(-1))\n",
    "recall_      = recall_score(y_validpred.reshape(-1), y_valid.reshape(-1)) \n",
    "\n",
    "print(\"LDA: precision %f recall %f \" % (precision_, recall_) ) \n",
    "precision_list.append(precision_)    \n",
    "recall_list.append(recall_) \n",
    "k_list.append(\"LDA\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qda.fit(X_train, y_train.reshape(-1))\n",
    "y_trainpred = qda.predict(X_train) \n",
    "\n",
    "y_validpred  = qda.predict(X_valid)\n",
    "precision_   = precision_score(y_validpred.reshape(-1), y_valid.reshape(-1))\n",
    "recall_      = recall_score(y_validpred.reshape(-1), y_valid.reshape(-1)) \n",
    "\n",
    "print(\"QDA: precision %f recall %f \" % (precision_, recall_) ) \n",
    "precision_list.append(precision_)    \n",
    "recall_list.append(recall_) \n",
    "k_list.append(\"QDA\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lda.predict(X_test) \n",
    "cm = confusion_matrix(y_test, predictions, labels=neigh.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = qda.predict(X_test) \n",
    "cm = confusion_matrix(y_test, predictions, labels=neigh.classes_)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=neigh.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EE575",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
