{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install numpy pandas tqdm matplotlib statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "- [5 scores] Select 5 features from house-price datasets. \n",
    "    - Pre-process the data ...\n",
    "    - Show the Correlation matrix of your selected features and explain why you choose them ....  \n",
    "\n",
    "- [15 scores] Apply the provided OLS to estimate the house-price... \n",
    "    \n",
    "    - [5 scores] Measue the performance of OLS with the following measurements:\n",
    "        - MAE \n",
    "        - RMSE\n",
    "        - R2score\n",
    "    \n",
    "    - [10 scores] At this setting, compute the following scores based on the training data\n",
    "        - loglikelihood.... ** We assume Gaussian case **...\n",
    "        - AIC\n",
    "        - BIC \n",
    "\n",
    "        Compare your results with loglikelihood, AIC, BIC, reported from statsmodel.sm.OLS()\n",
    "\n",
    "- [10 scores]  Improve the performance of the OLS by one of the following methods... \n",
    "    The minimum and maximum number of features are 1 and 10.\n",
    "\n",
    "    1. Feedforward features set selection\n",
    "    2. Backwad features set selection\n",
    "\n",
    "     \n",
    "- [10 scores]  Then, you have to show how you make decision by one of the following statistics: AIC, BIC, Adj. R-squared, and the validated MSE...\n",
    "\n",
    "- [5 scores] What ever decision you have made, please make sure that you have made the improvement on testing between the two models in terms of\n",
    "\n",
    "    - (1). MSE\n",
    "    - (2). Computational complexity \n",
    "\n",
    "\n",
    "- [5%**Extra]  If you can apply the iterative re-weight technique to improve the OLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt  \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the `house-prices` dataset from https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques/data or you can use the following command:\n",
    "\n",
    "`! kaggle competitions download -c house-prices-advanced-regression-techniques`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! kaggle competitions download -c house-prices-advanced-regression-techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "foldername = \"house-prices\"\n",
    "\n",
    "with zipfile.ZipFile(\"house-prices-advanced-regression-techniques.zip\",\"r\") as zip_ref:\n",
    "    zip_ref.extractall(foldername)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the csv file `train.csv` and `test.csv` ... \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Your target/label (for regression) is the house price\n",
    "- The rests of the attributes can be used as the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('%s/train.csv' % foldername)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Select 5 features from house-price datasets [5 scores] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.info() \n",
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My choices for 5 features are: .... \n",
    "\n",
    "1. HouseStyle  .... \n",
    "\n",
    "2. LotArea  ...\n",
    "\n",
    "3. YearBuilt ...\n",
    "\n",
    "4. Neighborhood ...\n",
    "\n",
    "5.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feat_List = ['HouseStyle']\n",
    "df[['HouseStyle']] = df.loc[:,['HouseStyle']].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "X = df.loc[:, Feat_List].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['SalePrice'].values.reshape(-1,1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if you need to encode any non-numerical attributes with value between 0 and n_classes-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Dimension dim:= 5\n",
      "Number Measurements (Training) m:= 1168\n",
      "Number Measurements (Testing)  n:= 292\n"
     ]
    }
   ],
   "source": [
    "Xscaler = StandardScaler()\n",
    "X_train        = Xscaler.fit_transform(X_train)\n",
    "X_test         = Xscaler.transform(X_test)\n",
    "\n",
    "Yscaler = StandardScaler()\n",
    "y_train        = Yscaler.fit_transform(y_train)  \n",
    "\n",
    "\n",
    "dim = X_train.shape[1] # dim:= Feature Dimension\n",
    "m = X_train.shape[0]   # m:= Number of Measurements(Training)\n",
    "n = X_test.shape[0]    # n:= Number of Measurements(Testing)\n",
    "\n",
    "print(\"Feature Dimension dim:= %d\" % dim)\n",
    "print(\"Number Measurements (Training) m:= %d\" % m)\n",
    "print(\"Number Measurements (Testing)  n:= %d\" % n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running OLS (First Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression \n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred_sk    = regressor.predict(X_test)\n",
    "y_pred_OLS = Yscaler.inverse_transform(y_pred_sk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== WLS =========================\n",
      "MAE: 43348.287631980325\n",
      "RMSE: 65411.63704981858\n",
      "R2score: 0.3804264089374024\n"
     ]
    }
   ],
   "source": [
    "print(\"================== WLS =========================\") \n",
    "print(\"MAE:\",metrics.mean_absolute_error(y_test,y_pred_OLS))\n",
    "print(\"RMSE:\",np.sqrt(metrics.mean_squared_error(y_test,y_pred_OLS))) \n",
    "print(\"R2score:\",metrics.r2_score(y_test,y_pred_OLS))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Log-likelihood, AIC, BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared (uncentered):</th>      <td>   0.371</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.368</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   137.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 23 Jan 2024</td> <th>  Prob (F-statistic):</th>          <td>2.53e-114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>23:47:58</td>     <th>  Log-Likelihood:    </th>          <td> -1386.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1168</td>      <th>  AIC:               </th>          <td>   2784.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1163</td>      <th>  BIC:               </th>          <td>   2809.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "   <td></td>     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th> <td>    0.0597</td> <td>    0.024</td> <td>    2.462</td> <td> 0.014</td> <td>    0.012</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th> <td>    0.2461</td> <td>    0.023</td> <td>   10.550</td> <td> 0.000</td> <td>    0.200</td> <td>    0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th> <td>    0.4681</td> <td>    0.025</td> <td>   18.865</td> <td> 0.000</td> <td>    0.419</td> <td>    0.517</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th> <td>    0.1338</td> <td>    0.023</td> <td>    5.720</td> <td> 0.000</td> <td>    0.088</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th> <td>    0.1213</td> <td>    0.024</td> <td>    5.102</td> <td> 0.000</td> <td>    0.075</td> <td>    0.168</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>557.656</td> <th>  Durbin-Watson:     </th> <td>   1.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4526.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.036</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.742</td>  <th>  Cond. No.          </th> <td>    1.44</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] R² is computed without centering (uncentered) since the model does not contain a constant.<br/>[2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared (uncentered):}      &     0.371   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared (uncentered):} &     0.368   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       }          &     137.0   \\\\\n",
       "\\textbf{Date:}             & Tue, 23 Jan 2024 & \\textbf{  Prob (F-statistic):}          & 2.53e-114   \\\\\n",
       "\\textbf{Time:}             &     23:47:58     & \\textbf{  Log-Likelihood:    }          &   -1386.8   \\\\\n",
       "\\textbf{No. Observations:} &        1168      & \\textbf{  AIC:               }          &     2784.   \\\\\n",
       "\\textbf{Df Residuals:}     &        1163      & \\textbf{  BIC:               }          &     2809.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     }          &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     }          &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{x1} &       0.0597  &        0.024     &     2.462  &         0.014        &        0.012    &        0.107     \\\\\n",
       "\\textbf{x2} &       0.2461  &        0.023     &    10.550  &         0.000        &        0.200    &        0.292     \\\\\n",
       "\\textbf{x3} &       0.4681  &        0.025     &    18.865  &         0.000        &        0.419    &        0.517     \\\\\n",
       "\\textbf{x4} &       0.1338  &        0.023     &     5.720  &         0.000        &        0.088    &        0.180     \\\\\n",
       "\\textbf{x5} &       0.1213  &        0.024     &     5.102  &         0.000        &        0.075    &        0.168     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 557.656 & \\textbf{  Durbin-Watson:     } &    1.995  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4526.237  \\\\\n",
       "\\textbf{Skew:}          &   2.036 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.742 & \\textbf{  Cond. No.          } &     1.44  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] R² is computed without centering (uncentered) since the model does not contain a constant. \\newline\n",
       " [2] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                      y   R-squared (uncentered):                   0.371\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.368\n",
       "Method:                 Least Squares   F-statistic:                              137.0\n",
       "Date:                Tue, 23 Jan 2024   Prob (F-statistic):                   2.53e-114\n",
       "Time:                        23:47:58   Log-Likelihood:                         -1386.8\n",
       "No. Observations:                1168   AIC:                                      2784.\n",
       "Df Residuals:                    1163   BIC:                                      2809.\n",
       "Df Model:                           5                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0597      0.024      2.462      0.014       0.012       0.107\n",
       "x2             0.2461      0.023     10.550      0.000       0.200       0.292\n",
       "x3             0.4681      0.025     18.865      0.000       0.419       0.517\n",
       "x4             0.1338      0.023      5.720      0.000       0.088       0.180\n",
       "x5             0.1213      0.024      5.102      0.000       0.075       0.168\n",
       "==============================================================================\n",
       "Omnibus:                      557.656   Durbin-Watson:                   1.995\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4526.237\n",
       "Skew:                           2.036   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.742   Cond. No.                         1.44\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
       "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm \n",
    "\n",
    "model   = sm.OLS(y_train, X_train)\n",
    "model = model.fit() \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_sk    = regressor.predict(X_train) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Forward/Backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  AIC/BIC/CV Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance on Testing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Bonus] Apply IRLS to this dataset..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
